# Analytics Performance Debugging Guide

## Comprehensive Debugging Added

### Frontend Debugging

#### 1. **App.js - Evaluations Loading**
```javascript
// Watch for these logs:
ğŸ”„ Loading evaluations for user {user_id}...
âœ… Evaluations loaded: {count} items in {duration}ms
âœ… Set {count} evaluations in state
âš ï¸ Slow evaluations fetch: {duration}ms for user {user_id}  // If > 3s
```

#### 2. **AnalyticsDashboard.js - Component State**
```javascript
// Check component state:
ğŸ” Analytics Dashboard State: {
  evaluations: [...],
  evaluationsType: "object",
  evaluationsIsArray: true,
  evaluationsLength: 92,
  hasEvaluations: true,
  isLoadingEvaluations: false,
  hasUnlimitedAccess: true
}
```

#### 3. **Analytics Service - API Call**
```javascript
// Track API flow:
ğŸ” [Analytics Service] Starting getUserAnalytics for user: {user_id}
ğŸ” [Analytics Service] Full URL: /analytics/{user_id}
ğŸ“¡ [Analytics Service] Making API request...
âœ… [Analytics Service] API request completed in {duration}ms
ğŸ“¦ [Analytics Service] Response data: {
  status: 200,
  hasData: true,
  dataKeys: ["analytics"]
}
```

#### 4. **AnalyticsDashboard - AI Insights Fetch**
```javascript
// When user clicks "Generate AI Insights":
ğŸš€ [Analytics] Starting AI insights fetch for user: {user_id}
ğŸ” [Analytics] Calling getUserAnalytics...
âœ… [Analytics] getUserAnalytics completed in {duration}ms
ğŸ“Š [Analytics] Response data: {
  hasData: true,
  hasAnalytics: true,
  hasRecommendations: true,
  recommendationsLength: 1234,
  totalResponses: 92
}
âœ… [Analytics] State updated successfully
```

### Backend Debugging

#### 1. **Analytics Endpoint - Overall Flow**
```python
# Watch for these logs in backend/backend.log:
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Analytics request START for user: {user_id}
ğŸ“Š Timestamp: 2025-10-01T...
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### 2. **User Validation**
```python
ğŸ” Fetching user data for: {user_id}
âœ… User found: {user_id}, plan: unlimited
```

#### 3. **Evaluations Fetch**
```python
ğŸ” Fetching evaluations from Supabase for user: {user_id}
âœ… Retrieved 92 evaluations in 0.23s
```

#### 4. **Recommendations Processing**
```python
ğŸ§  Recommendations check: 92 evaluations
âœ… User has 92 evaluations, checking for recommendations...
ğŸ”„ Refresh needed? true/false (evaluations % 5 == 0)
ğŸ” Looking for cached recommendations with key: recos_{user_id}
ğŸ“¦ Cache lookup completed in 0.15s, found: true/false
```

#### 5. **AI Generation (if needed)**
```python
ğŸš€ Generating new AI recommendations...
ğŸ¯ Calling AI recommendations with {count} question type summaries
ğŸ¤– Starting AI recommendations API call...
ğŸ“¡ Calling OpenRouter API with model: openai/gpt-oss-120b
âœ… OpenRouter API responded in 3.45s, status: 200
ğŸ“ AI response length: 1234 characters
âœ… AI recommendations generated in 3.50s
```

#### 6. **Cache Save**
```python
ğŸ’¾ Caching AI recommendations...
ğŸ”„ Updating existing cache entry  // OR
â• Creating new cache entry
âœ… Cache saved in 0.12s
âœ… Using newly generated recommendations (1234 chars)
```

#### 7. **Or Using Cache**
```python
â™»ï¸ Using cached recommendations (1234 chars)
```

#### 8. **Final Response**
```python
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Analytics request COMPLETE for user: {user_id}
â±ï¸ Total duration: 4.23s
ğŸ“¦ Returning 92 evaluations + 1234 chars of recommendations
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## How to Debug

### Step 1: Open Browser Console
```
1. Navigate to Analytics page (/analytics)
2. Open Chrome DevTools (F12)
3. Go to Console tab
4. Filter for "[Analytics"
```

### Step 2: Monitor Backend Logs
```bash
cd /home/josh/Downloads/EEnglishGPT-main-main/backend
tail -f backend.log | grep -E "Analytics|Recommendations|evaluations"
```

### Step 3: Click "Generate AI Insights"
Watch both console and backend logs simultaneously.

### Expected Flow (First Time - No Cache)

**Frontend Console:**
```
ğŸš€ [Analytics] Starting AI insights fetch for user: 639cd1d6-...
ğŸ” [Analytics Service] Starting getUserAnalytics for user: 639cd1d6-...
ğŸ” [Analytics Service] Full URL: /analytics/639cd1d6-...
ğŸ“¡ [Analytics Service] Making API request...
[... wait 3-5 seconds for AI ...]
âœ… [Analytics Service] API request completed in 4523ms
ğŸ“Š [Analytics] Response data: { hasRecommendations: true, ... }
âœ… [Analytics] State updated successfully
```

**Backend Log:**
```
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Analytics request START for user: 639cd1d6-...
ğŸ” Fetching user data...
âœ… User found: unlimited
ğŸ” Fetching evaluations from Supabase...
âœ… Retrieved 92 evaluations in 0.23s
ğŸ§  Recommendations check: 92 evaluations
ğŸ” Looking for cached recommendations...
ğŸ“¦ Cache lookup completed in 0.15s, found: false
ğŸš€ Generating new AI recommendations...
ğŸ¤– Starting AI recommendations API call...
ğŸ“¡ Calling OpenRouter API...
âœ… OpenRouter API responded in 3.45s
âœ… AI recommendations generated in 3.50s
ğŸ’¾ Caching AI recommendations...
âœ… Cache saved in 0.12s
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Analytics request COMPLETE
â±ï¸ Total duration: 4.23s
ğŸ“Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Expected Flow (Cached)

**Frontend Console:**
```
[Same as above but much faster]
âœ… [Analytics Service] API request completed in 342ms  // Much faster!
```

**Backend Log:**
```
ğŸ“Š Analytics request START...
âœ… Retrieved 92 evaluations in 0.23s
ğŸ” Looking for cached recommendations...
ğŸ“¦ Cache lookup completed in 0.08s, found: true
â™»ï¸ Using cached recommendations (1234 chars)
â±ï¸ Total duration: 0.45s  // Much faster!
```

## Performance Benchmarks

### Acceptable Durations

**First Time (No Cache):**
- Evaluations fetch: < 1s
- Cache lookup: < 0.2s
- AI generation: 3-8s (normal for AI)
- Cache save: < 0.5s
- **Total: 4-10s** âœ… Acceptable

**Cached:**
- Evaluations fetch: < 1s
- Cache lookup: < 0.2s
- Cache retrieval: < 0.1s
- **Total: < 1.5s** âœ… Excellent

### Warning Signs

**Slow Evaluations (> 3s):**
- Check Supabase connection
- Check network latency
- Check evaluation count (too many?)

**Slow AI Generation (> 15s):**
- Check OpenRouter API status
- Check API key validity
- Check rate limits

**Slow Cache Operations (> 1s):**
- Check Supabase connection
- Check table indexes
- Check database performance

## Troubleshooting

### Problem: "No Analytics Data Yet"

**Check:**
1. Browser console: `ğŸ” Analytics Dashboard State`
   - Is `evaluationsLength` > 0?
   - Is `isLoadingEvaluations` false?
2. Backend log: Did evaluations fetch succeed?
3. App.js console: `âœ… Evaluations loaded: X items`

**Solution:**
- If evaluations not loading: Check `/api/evaluations/user/{user_id}` endpoint
- If loading stuck: Check frontend `evaluationsLoading` state
- If null: Check App.js useEffect dependency array

### Problem: AI Insights Not Working

**Check:**
1. Click "Generate AI Insights" button
2. Frontend console: Does it say "Starting AI insights fetch"?
3. Frontend console: Any errors?
4. Backend log: Is analytics endpoint being called?
5. Backend log: Any recommendations errors?

**Common Issues:**
```
âŒ OPENROUTER_GPT_OSS_120B_KEY not configured
â†’ Solution: Check backend/.env has OPENROUTER_GPT_OSS_120B_KEY

âŒ User has only 4 evaluations, need 5+ for recommendations
â†’ Solution: Complete more assessments

âŒ Cache lookup failed
â†’ Solution: Check Supabase permissions for assessment_meta table

âŒ OpenRouter API timeout
â†’ Solution: Check API status, increase timeout
```

### Problem: Loading Takes Too Long

**Check Backend Log:**
```bash
tail -f backend/backend.log | grep "â±ï¸ Total duration"
```

**If > 10s:**
1. Check which step is slow:
   - Evaluations fetch?
   - AI generation?
   - Cache operations?
2. Check network connectivity
3. Check API rate limits
4. Consider increasing timeouts

## Testing Commands

### Test Analytics Endpoint Directly
```bash
# Check if endpoint works
curl -X GET "http://localhost:8000/api/analytics/639cd1d6-4d7e-44e4-aea5-9251c0061900" \
  -H "Authorization: Bearer YOUR_TOKEN" | jq '.'
```

### Test Evaluations Endpoint
```bash
curl -X GET "http://localhost:8000/api/evaluations/user/639cd1d6-4d7e-44e4-aea5-9251c0061900" \
  -H "Authorization: Bearer YOUR_TOKEN" | jq '.evaluations | length'
```

### Monitor Real-Time Logs
```bash
# Terminal 1: Backend logs
tail -f backend/backend.log

# Terminal 2: Filter for analytics only
tail -f backend/backend.log | grep "Analytics\|Recommendations"
```

## Performance Optimization

If analytics is consistently slow:

### 1. Database Optimization
- Add indexes to `assessment_evaluations` table:
  ```sql
  CREATE INDEX idx_user_timestamp ON assessment_evaluations(user_id, timestamp DESC);
  ```

### 2. Reduce AI Calls
- Increase cache validity (currently every 5 evaluations)
- Add manual refresh button only (already done!)

### 3. Lazy Load Evaluations
- Don't fetch all 92 at once
- Fetch summary first, details on demand

### 4. Add Loading Progress
- Show progress bar during AI generation
- Display "Analyzing X of Y question types..."

## Success Criteria

### Analytics Should:
âœ… Load in < 2s when cached
âœ… Generate AI insights in < 10s when not cached
âœ… Show loading state while fetching
âœ… Display error messages if something fails
âœ… Cache recommendations properly
âœ… Show accurate evaluation count

### Logs Should Show:
âœ… Clear start/end boundaries
âœ… Timing for each major step
âœ… Success/error indicators
âœ… Data sizes being processed

## Next Steps After Debugging

1. Review console logs for any errors
2. Check backend logs for performance bottlenecks
3. Verify evaluations are loading (count should be > 0)
4. Click "Generate AI Insights" and watch both logs
5. Report any errors found with specific log output

